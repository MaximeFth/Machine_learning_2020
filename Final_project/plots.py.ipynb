{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from grid_search import get_best_parameters\n",
    "\n",
    "\n",
    "def prediction(w0, w1, mean_x, std_x):\n",
    "    \"\"\"Get the regression line from the model.\"\"\"\n",
    "    x = np.arange(1.2, 2, 0.01)\n",
    "    x_normalized = (x - mean_x) / std_x\n",
    "    return x, w0 + w1 * x_normalized\n",
    "\n",
    "\n",
    "def base_visualization(grid_losses, w0_list, w1_list,\n",
    "                       mean_x, std_x, height, weight):\n",
    "    \"\"\"Base Visualization for both models.\"\"\"\n",
    "    w0, w1 = np.meshgrid(w0_list, w1_list)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # plot contourf\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    cp = ax1.contourf(w0, w1, grid_losses.T, cmap=plt.cm.jet)\n",
    "    fig.colorbar(cp, ax=ax1)\n",
    "    ax1.set_xlabel(r'$w_0$')\n",
    "    ax1.set_ylabel(r'$w_1$')\n",
    "    # put a marker at the minimum\n",
    "    loss_star, w0_star, w1_star = get_best_parameters(\n",
    "        w0_list, w1_list, grid_losses)\n",
    "    ax1.plot(w0_star, w1_star, marker='*', color='r', markersize=20)\n",
    "\n",
    "    # plot f(x)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.scatter(height, weight, marker=\".\", color='b', s=5)\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"y\")\n",
    "    ax2.grid()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def grid_visualization(grid_losses, w0_list, w1_list,\n",
    "                       mean_x, std_x, height, weight):\n",
    "    \"\"\"Visualize how the trained model looks like under the grid search.\"\"\"\n",
    "    fig = base_visualization(\n",
    "        grid_losses, w0_list, w1_list, mean_x, std_x, height, weight)\n",
    "\n",
    "    loss_star, w0_star, w1_star = get_best_parameters(\n",
    "        w0_list, w1_list, grid_losses)\n",
    "    # plot prediciton\n",
    "    x, f = prediction(w0_star, w1_star, mean_x, std_x)\n",
    "    ax2 = fig.get_axes()[2]\n",
    "    ax2.plot(x, f, 'r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def gradient_descent_visualization(\n",
    "        gradient_losses, gradient_ws,\n",
    "        grid_losses, grid_w0, grid_w1,\n",
    "        mean_x, std_x, height, weight, n_iter=None):\n",
    "    \"\"\"Visualize how the loss value changes until n_iter.\"\"\"\n",
    "    fig = base_visualization(\n",
    "        grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "\n",
    "    ws_to_be_plotted = np.stack(gradient_ws)\n",
    "    if n_iter is not None:\n",
    "        ws_to_be_plotted = ws_to_be_plotted[:n_iter]\n",
    "\n",
    "    ax1, ax2 = fig.get_axes()[0], fig.get_axes()[2]\n",
    "    ax1.plot(\n",
    "        ws_to_be_plotted[:, 0], ws_to_be_plotted[:, 1],\n",
    "        marker='o', color='w', markersize=10)\n",
    "    pred_x, pred_y = prediction(\n",
    "        ws_to_be_plotted[-1, 0], ws_to_be_plotted[-1, 1],\n",
    "        mean_x, std_x)\n",
    "    ax2.plot(pred_x, pred_y, 'r')\n",
    "\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
