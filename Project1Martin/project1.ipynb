{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"trainFile.csv\"#\"C:/Users/Martin/Desktop/Workspace/Machine_Learning/data/data/trainFile.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "def standardize(x):\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    return std_data\n",
    "tX = standardize(tX)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others Usefull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_loss_logisitic(y,tx,w):\n",
    "    result = tx.T@(delta(tx@w) -y)\n",
    "    return result\n",
    "\n",
    "def compute_loss_regression(y,tx,w, lambda_):\n",
    "    return np.sum( np.log((1-y)/2 + y*delta(tx@w))) + (lambda_/2)*np.sum(w**2)\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    N = y.shape[0]\n",
    "    e = y - (tx @ w)\n",
    "    result = 1/(2*N) * (np.transpose(e) @ e)\n",
    "    return result\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    solution =  -(1/y.shape[0])*(np.transpose(tx) @ (y - (tx @ w)))\n",
    "    return solution\n",
    "\n",
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    #Here N  =1\n",
    "    solution =  -(1/2)*(tx.T.dot(y - (tx @ w)))\n",
    "    return solution\n",
    "\n",
    "def delta(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\"\"\"\n",
    "    result = np.zeros((x.shape[0], x.shape[1]*(degree+1)))\n",
    "    \n",
    "    for i in range(degree+1):\n",
    "        result[:,x.shape[1]*i:x.shape[1]*(i+1)] = np.power(x,i)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        w = w -gamma*gradient\n",
    "\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w,max_iters, gamma):\n",
    "    w = initial_w\n",
    "    losses=[]\n",
    "    for n_iter in range(max_iters):\n",
    "        i = np.random.randint(y.shape[0])\n",
    "        gradient = compute_stoch_gradient(y[i],tx[i],w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares and solving equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    x = tx\n",
    "    gram = x.T @ x\n",
    "    if np.linalg.det(gram)!=0:\n",
    "        w = np.linalg.inv(gram)@x.T@y\n",
    "    else:\n",
    "        w = np.linealt.solv(gram,x.T@y)\n",
    "    return w, compute_loss(y,tx,w)\n",
    "## Least squares using Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    #Using L2\n",
    "    lambdaPrime = lambda_*(2*tx.shape[0])\n",
    "    x = tx\n",
    "    gramLambda = x.T@x + np.eye(x.shape[1])*lambdaPrime\n",
    "    if np.linalg.det(gramLambda)!=0:\n",
    "        w = np.linalg.inv(gramLambda)@x.T@y\n",
    "    else:\n",
    "         w = np.linealt.solv(gramLambda,x.T@y)\n",
    "    return w, compute_loss(y,tx,w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression(y, tx, initial_w,max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_it in range(max_iters):\n",
    "        #loss = compute_loss_logisitic(y,tx,w)\n",
    "        gradient = compute_loss_logisitic(y,tx,w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressive Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_,initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss_regression(y,tx,w, lambda_)\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Weight : Linear regression using gradient descent \n",
    "inital_w = np.zeros(30)\n",
    "loss = []\n",
    "weightGD, lossGD = least_squares_GD(y, tX, inital_w, 50, 0.1)\n",
    "loss.append(lossGD)\n",
    "weightSGD, lossSGD = least_squares_SGD(y, tX, inital_w, 50, 0.01)\n",
    "loss.append(lossSGD)\n",
    "weightLS, lossLS = least_squares(y, tX)\n",
    "loss.append(lossLS)\n",
    "weightRR, lossRR = ridge_regression(y, tX, 1)\n",
    "loss.append(lossRR)\n",
    "\n",
    "weightsLR,_ = logistic_regression(y, tX, inital_w, 50, 0.00000001)\n",
    "loss.append(compute_loss(y,tX,weightsLR))\n",
    "\n",
    "\n",
    "weightsRLR,_ = reg_logistic_regression(y, tX, 1, inital_w, 50, 0.1)\n",
    "loss.append(compute_loss(y,tX,weightsRLR))\n",
    "print(loss)\n",
    "#plot(lossSGD)\n",
    "print(\"DONE\")\n",
    "print(\"DONE\")\n",
    "\n",
    "## Regressive Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TEST_PATH = 'testFile.csv' # TODO: download train data and supply path here \n",
    "print(\"done\")\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "print(\"done\")\n",
    "\n",
    "y_pred = predict_labels(weightLS, tX_test)\n",
    "print(\"done\")\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
