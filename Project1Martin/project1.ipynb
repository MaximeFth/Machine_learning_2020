{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = \"trainFile.csv\"#\"C:/Users/Martin/Desktop/Workspace/Machine_Learning/data/data/trainFile.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "def standardize(x):\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    return std_data\n",
    "tX = standardize(tX)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others Usefull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_loss_logisitic(y,tx,w):\n",
    "    result = tx.T@(delta(tx@w) -y)\n",
    "    return result\n",
    "\n",
    "def compute_loss_regression(y,tx,w, lambda_):\n",
    "    return np.sum( np.log((1-y)/2 + y*delta(tx@w))) + (lambda_/2)*np.sum(w**2)\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    N = y.shape[0]\n",
    "    e = y - (tx @ w)\n",
    "    result = 1/(2*N) * (np.transpose(e) @ e)\n",
    "    return result\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    solution =  -(1/y.shape[0])*(np.transpose(tx) @ (y - (tx @ w)))\n",
    "    return solution\n",
    "\n",
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    #Here N  =1\n",
    "    solution =  -(1/2)*(tx.T.dot(y - (tx @ w)))\n",
    "    return solution\n",
    "\n",
    "def delta(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        w = w -gamma*gradient\n",
    "\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w,max_iters, gamma):\n",
    "    w = initial_w\n",
    "    losses=[]\n",
    "    for n_iter in range(max_iters):\n",
    "        i = np.random.randint(y.shape[0])\n",
    "        gradient = compute_stoch_gradient(y[i],tx[i],w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares and solving equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    x = tx\n",
    "    gram = x.T @ x\n",
    "    if np.linalg.det(gram)!=0:\n",
    "        w = np.linalg.inv(gram)@x.T@y\n",
    "    else:\n",
    "        w = np.linealt.solv(gram,x.T@y)\n",
    "    return w, compute_loss(y,tx,w)\n",
    "## Least squares using Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    #Using L2\n",
    "    lambdaPrime = lambda_*(2*tx.shape[0])\n",
    "    x = tx\n",
    "    gramLambda = x.T@x + np.eye(x.shape[1])*lambdaPrime\n",
    "    if np.linalg.det(gramLambda)!=0:\n",
    "        w = np.linalg.inv(gramLambda)@x.T@y\n",
    "    else:\n",
    "         w = np.linealt.solv(gramLambda,x.T@y)\n",
    "    return w, compute_loss(y,tx,w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_regression(y, tx, initial_w,max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_it in range(max_iters):\n",
    "        #loss = compute_loss_logisitic(y,tx,w)\n",
    "        gradient = compute_loss_logisitic(y,tx,w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressive Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_,initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        loss = compute_loss_regression(y,tx,w, lambda_)\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        w = w - gamma*gradient\n",
    "    return w, compute_loss(y,tx,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3991067428443696, 0.4756741453995229, 0.3889523149681917, 0.4361889210773641, 0.45953340107729224, 0.3988914575644723]\n",
      "DONE\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#Weight : Linear regression using gradient descent \n",
    "inital_w = np.zeros(30)\n",
    "loss = []\n",
    "weightGD, lossGD = least_squares_GD(y, tX, inital_w, 50, 0.1)\n",
    "loss.append(lossGD)\n",
    "weightSGD, lossSGD = least_squares_SGD(y, tX, inital_w, 50, 0.01)\n",
    "loss.append(lossSGD)\n",
    "weightLS, lossLS = least_squares(y, tX)\n",
    "loss.append(lossLS)\n",
    "weightRR, lossRR = ridge_regression(y, tX, 1)\n",
    "loss.append(lossRR)\n",
    "\n",
    "weightsLR,_ = logistic_regression(y, tX, inital_w, 50, 0.00000001)\n",
    "loss.append(compute_loss(y,tX,weightsLR))\n",
    "\n",
    "\n",
    "weightsRLR,_ = reg_logistic_regression(y, tX, 1, inital_w, 50, 0.1)\n",
    "loss.append(compute_loss(y,tX,weightsRLR))\n",
    "print(loss)\n",
    "#plot(lossSGD)\n",
    "print(\"DONE\")\n",
    "print(\"DONE\")\n",
    "\n",
    "## Regressive Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weightSGD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0abe1b4507f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweightSGD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weightSGD' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TEST_PATH = 'testFile.csv' # TODO: download train data and supply path here \n",
    "print(\"done\")\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = 'result.csv' # TODO: fill in desired name of output file for submission\n",
    "print(\"done\")\n",
    "\n",
    "y_pred = predict_labels(weightLS, tX_test)\n",
    "print(\"done\")\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
