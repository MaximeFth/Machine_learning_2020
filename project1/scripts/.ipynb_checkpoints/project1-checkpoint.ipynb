{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "from costs import compute_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "# standardize the data\n",
    "tX_std = standardize(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement ML methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    # ***************************************************\n",
    "    return (-1/len(y))*tx.T@(y-tx@w)\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"least square gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # compute gradient computes the gradient\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        # compute loss. here MSE is used\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        # ***************************************************\n",
    "        # TODO: update w by gradient\n",
    "        w = w-gamma*gradient\n",
    "        # ***************************************************\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.array(losses), np.array(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## least square SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    # ***************************************************\n",
    "    e = y-tx@w\n",
    "    return -1/len(y)*tx.T@e\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Least square stochastic gradient descent algorithm.\"\"\"\n",
    "    # ***************************************************\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute random batch\n",
    "        a = batch_iter(y, tx, batch_size, num_batches=1, shuffle=True)\n",
    "        a = list(a)\n",
    "        tx2, y2 = a[0][1], a[0][0]\n",
    "        \n",
    "        # compute gradient & loss\n",
    "        grad = compute_stoch_gradient(y2,tx2,w)\n",
    "        loss= compute_loss(y2, tx2, w)\n",
    "        print(grad)\n",
    "        # update gradient\n",
    "        w = w-gamma*grad\n",
    "        \n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        #print(\"stoch Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              #bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    return np.array(losses), np.array(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## least square\n",
    "computed by solving for w:  X<sup>T</sup>X * w = X<sup>T</sup>y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(y, tx):\n",
    "    w = np.linalg.solve(tx.T@tx,tx.T@y)\n",
    "    return w, compute_loss(y, tx, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls, loss = least_square(y, tX_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lamda):\n",
    "    w = np.linalg.solve(tx.T@tx+lamda*np.eye(tx.shape[1]),tx.T@y)\n",
    "    return w, compute_loss(y, tx, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7779046298744507\n"
     ]
    }
   ],
   "source": [
    "wls, loss = ridge_regression(y, tX_std,0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def update_weights(tx, y, w, gamma):\n",
    "    #probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    gradient = np.dot(tx.T,  probabilities - y)\n",
    "    w -= gradient*gamma / len(tx)\n",
    "    return w\n",
    "\n",
    "def loss_function_LR(tx, y, w):\n",
    "    #probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    #the error when label=1\n",
    "    error1 = -y*np.log(probabilities)\n",
    "    #the error when label=-1\n",
    "    error2 = (1-y)*np.log(1-probabilities)\n",
    "    #return average of sum of costs\n",
    "    return (error1-error2).mean()\n",
    "\n",
    "\n",
    "# logistic regression function\n",
    "def logistic_regression(y,tx, initial_w,  max_iter, gamma):\n",
    "    losses = []\n",
    "    ws = []\n",
    "    for iter_n in range(max_iter):\n",
    "        w = update_weights(tx, y, initial_w, gamma)\n",
    "        loss = loss_function_LR(tx, y, w)\n",
    "        losses.append(loss)\n",
    "        ws.append(w)\n",
    "    return np.array(losses)[-1], np.array(ws)[-1]\n",
    "\n",
    "#################################################################################\n",
    "def decision_boundary(prob):\n",
    "    return 1 if prob > 0.5 else -1\n",
    "\n",
    "def classify(predictions):\n",
    "    decision_boundary = np.vectorize(decision_boundary)\n",
    "    return decision_boundary(predictions).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_LR_update_weights(tx, y, w, gamma, lambda_):\n",
    "    \"\"\"\n",
    "    Update weights function for  regularized logistic regression\n",
    "    \n",
    "    :param tx: features matrix\n",
    "    :param y: labels vector\n",
    "    :param w: weights\n",
    "    :param gamma: learning rate\n",
    "    :param lambda_: regulizer\n",
    "    \n",
    "    :return w: new updated weights\n",
    "    \"\"\" \n",
    "    # probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    gradient = np.dot(tx.T,  probabilities - y) + lambda_ * w\n",
    "    w -= gradient*gamma / len(tx)\n",
    "    return w\n",
    "\n",
    "def reg_LR_loss_function(tx, y, w, lambda_):\n",
    "    \"\"\"\n",
    "    Computes logistic loss\n",
    "    \n",
    "    :param tx: features matrix\n",
    "    :param y: labels vector\n",
    "    :param w: weights\n",
    "    :param lambda_: regulizer\n",
    "    \n",
    "    :return w: logistic loss\n",
    "    \"\"\" \n",
    "    # probabilities array that the label is 1\n",
    "    probabilities = sigmoid(tx_@w)\n",
    "    # the error when label=1\n",
    "    error1 = -y_*np.log(probabilities)\n",
    "    # the error when label=-1\n",
    "    error2 = (1-y_)*np.log(1-probabilities)\n",
    "    # return average of sum of costs\n",
    "    return (error1-error2).mean()+lambda_/2*np.dot(w.T,w)/ len(tx_)\n",
    "\n",
    "\n",
    "# regularized logistic regression function\n",
    "def reg_logistic_regression(y,tx, initial_w,max_iter, gamma,lambda_):\n",
    "    \"\"\"\n",
    "    Regularized logistic regression function\n",
    "    \n",
    "    :param tx: features matrix\n",
    "    :param y: labels vector\n",
    "    :param initial_w: initial weights\n",
    "    :param max_iter: number of iterations\n",
    "    :param gamma: learning rate\n",
    "    :param lambda_: regulizer\n",
    "\n",
    "    :return ls: last loss  computed\n",
    "    :return ws: last weights computed\n",
    "    \"\"\" \n",
    "    losses = []\n",
    "    ws = []\n",
    "    for iter_n in range(max_iter):\n",
    "        w = reg_LR_update_weights(tx, y, initial_w, gamma,lambda_)\n",
    "        loss = reg_LR_loss_function(tx, y, w, lambda_)\n",
    "        losses.append(loss)\n",
    "        ws.append(w)\n",
    "    ls, ws  = np.array(losses)[-1], np.array(ws)[-1]\n",
    "    return ls,ws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def parallel_shuffle(a, b):\n",
    "    \"\"\"\n",
    "    shuffle 2 arrays numpy accordingly to each other.\n",
    "    :param a: numpy array a\n",
    "    :param b: numpy array b\n",
    "    \"\"\" \n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "def split_cross_KFold(K, tx, y):\n",
    "    \"\"\"\n",
    "    Compute K pairs of validations sets  of length 250'000/K and train set of size 250'000 - 250'000/K\n",
    "    \n",
    "    :param K: number of folds\n",
    "    :param tx: features matrix\n",
    "    :param y: labels vector\n",
    "    \"\"\" \n",
    "    temp_tx = np.copy(tx)\n",
    "    temp_y = np.copy(y)\n",
    "    #parallel_shuffle(temp_tx,temp_y)\n",
    "    train_set, val_set = [], []\n",
    "    size = temp_tx.shape[0]//K\n",
    "    for i in range(K):\n",
    "        val_set.append((temp_tx[size*i:size+size*i], temp_y[size*i:size+size*i]))\n",
    "        indices = range(size*i,size+size*i)\n",
    "        train_set.append((np.delete(temp_tx, indices, axis = 0),np.delete(temp_y, indices, axis = 0)))\n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions updated for K-fold cross validation\n",
    "we compute now the loss on the validations sets instead of the train ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD_val(tx_val,y_val,tx,y, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Least square stochastic gradient descent algorithm.\"\"\"\n",
    "    # ***************************************************\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute random batch\n",
    "        a = batch_iter(y, tx, batch_size, num_batches=1, shuffle=True)\n",
    "        a = list(a)\n",
    "        tx2, y2 = a[0][1], a[0][0]\n",
    "        \n",
    "        # compute gradient & loss\n",
    "        grad = compute_stoch_gradient(y2,tx2,w)\n",
    "        loss= compute_loss(y_val, tx_val, w)\n",
    "        # update gradient\n",
    "        w = w-gamma*grad\n",
    "        # diminish gamma at each iteration\n",
    "        gamma = gamma - gamma/10\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        #print(\"stoch Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              #bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    return np.array(losses), np.array(ws)\n",
    "\n",
    "def evalutate_Kfold_SGD(train_set,validation_set,iters, gamma,K,batch_size, plot=1):\n",
    "    graph = []\n",
    "    weigths_final = []\n",
    "    validation_losses = []\n",
    "    train_losses = []\n",
    "    for i in range(K):\n",
    "        max_iters = iters\n",
    "        # Initialization\n",
    "        w_initial = np.zeros(30)\n",
    "        # validation set [i][0] is matrice tx of the validation set i\n",
    "        # validation set [i][1] is vector y of the validation set i\n",
    "        validation_losses, ws  = least_squares_SGD_val(validation_set[i][0],validation_set[i][1], train_set[i][0], train_set[i][1], w_initial,  batch_size, max_iters, gamma)\n",
    "        #compute train_loss\n",
    "        train_loss = loss_function(train_set[i][0], train_set[i][1], ws)\n",
    "        validation_losses.append(validation_loss[-1])\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        weigths_final.append(ws)\n",
    "        \n",
    "        if plot:\n",
    "            graph.append(losses)\n",
    "    if plot:\n",
    "        G = plt.plot(np.array(graph).T)\n",
    "        leg = [\"\"+str(i) for i in range(K)]\n",
    "        plt.legend(G[:K], leg)\n",
    "        \n",
    "    return weigths_final, validation_losses, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regularized Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update logistic regression in order to compute loss on validation set\n",
    "def reg_logistic_regression_val(tx_val,y_val,tx_train,y_train, initial_w,  max_iter, gamma,lambda_):\n",
    "    \"\"\"\n",
    "    regularized logistic regression function \n",
    "    \n",
    "    :param tx_val: validation set features \n",
    "    :param y_val: validation set labels\n",
    "    :param tx_train: training set features \n",
    "    :param y_train: training set labels\n",
    "    :param initial_w: initial weights\n",
    "    :param max_iter: number of iteration for the GD\n",
    "    :param gamma: learning rate\n",
    "    :param lambda_: regulizer\n",
    "    :return: array of losses for validation set, train set, and best weights\n",
    "    \"\"\" \n",
    "    losses_val = []\n",
    "    losses_train = []\n",
    "    ws = []\n",
    "    for iter_n in range(max_iter):\n",
    "        # update weights by gradient descent\n",
    "        \n",
    "        w = reg_LR_update_weights(tx_train, y_train, initial_w, gamma,lambda_)\n",
    "        # compute loss on validation sets according to weights w\n",
    "        loss_train = reg_LR_loss_function(tx_train, y_train, w,lambda_)\n",
    "        loss_val = reg_LR_loss_function(tx_val, y_val, w,lambda_)\n",
    "        losses_train.append(loss_train)\n",
    "        losses_val.append(loss_val)\n",
    "\n",
    "        ws.append(w)\n",
    "            \n",
    "    return np.array(losses_val), np.array(losses_train), np.array(ws)[-1]\n",
    "\n",
    "\n",
    "def evaluate_Kfold_logistic(train_set,validation_set,iters, gamma,K,lambda_=0):\n",
    "    \"\"\"\n",
    "    evaluation of regularized logistic regression function. The function will plot \n",
    "    the graphs of the training and validation losts\n",
    "    \n",
    "    :param train_set: validation set features \n",
    "    :param validation_set: validation set labels\n",
    "    :param iter: number of iteration for the GD\n",
    "    :param gamma: learning rate\n",
    "    :param lambda_: regulizer\n",
    "\n",
    "    :return: array of losses for validation set, train set, and best weights\n",
    "    \"\"\" \n",
    "    graph_train = []\n",
    "    graph_val = []\n",
    "    weigths_final = []\n",
    "    validation_losses = []\n",
    "    train_losses = []\n",
    "\n",
    "    for i in range(K):\n",
    "        max_iters = iters\n",
    "        # Initialization\n",
    "        w_initial = np.zeros(len(train_set[0][0][1]))\n",
    "        # validation set [i][0] is matrice tx of the validation set i\n",
    "        # validation set [i][1] is vector y of the validation set i\n",
    "        validation_loss,train_loss, ws  = reg_logistic_regression_val(validation_set[i][0],validation_set[i][1], train_set[i][0], train_set[i][1], w_initial, max_iters, gamma, lambda_)\n",
    "        \n",
    "        validation_losses.append(validation_loss[-1])\n",
    "        train_losses.append(train_loss[-1])\n",
    "\n",
    "        weigths_final.append(ws)\n",
    "        \n",
    "        graph_val.append(validation_loss)\n",
    "        graph_train.append(train_loss)\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    G = plt.plot(np.array(graph_val).T)\n",
    "    leg = [\"val \"+str(i) for i in range(K)]\n",
    "    plt.legend(G[:K], leg)\n",
    "    plt.subplot(212)\n",
    "    G2 = plt.plot(np.array(graph_train).T)\n",
    "    leg2 = [\"train \"+str(i) for i in range(K)]\n",
    "    plt.legend(G2[:K], leg2)\n",
    "        \n",
    "    return weigths_final, validation_losses, train_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# standardize the data\n",
    "tX_std = standardize(tX)\n",
    "y_std = (y+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put feature exp here\n",
    "\n",
    "def fesquare(tx):\n",
    "    temp = np.copy(tx)\n",
    "    return np.concatenate((temp,temp**2),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Model,tx_std,y_std,gamma,max_iter = 200,K=5, batch_size=1,lambda_=0):\n",
    "    \"\"\"\n",
    "    regularized logistic regression function \n",
    "    \n",
    "    :param Model: model that we'll use\n",
    "    :param tx_std: standardized features matrix\n",
    "    :param y_std: standardized labels vector\n",
    "    :param gamma: learning rate\n",
    "    :param max_iter: number of iteration for the GD\n",
    "    :param K: cross validation part size\n",
    "    :param batch_size: for SGD only, if we want to change it\n",
    "    :param lambda_: regulizer\n",
    "    :return wf: final weights \n",
    "    \"\"\"    \n",
    "    assert( K > 1)\n",
    "    #feature expansion\n",
    "    tX_std_expanded = fesquare(tX_std)\n",
    "    # perform K pairs for the cross validation\n",
    "    train_set, val_set = split_cross_KFold(K, tX_std_expanded, y_std)\n",
    "    if Model == 'Log_reg':\n",
    "        wf, validation_lost, train_loss = evaluate_Kfold_logistic(train_set, val_set, max_iter,gamma,K,lambda_ )\n",
    "    if Model == 'SGD':\n",
    "        wf, validation_lost, train_loss = evalutate_Kfold_SGD(train_set, val_set, max_iter ,gamma,K,batch_size,lambda_ )\n",
    "        \n",
    "        \n",
    "    print(f'Function: {Model} used, K = {K}, Best final loss :{np.min(validation_lost)}')\n",
    "    for i in range(len(validation_lost)):\n",
    "        print(f'validation_lost {i}: {str(validation_lost[i])[:6]} , train_loss {i}: {str(train_loss[i])[:6]}')\n",
    "    print(f'mean validation lost: {np.mean(validation_lost)}')\n",
    "    return wf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: Log_reg used, K = 5, Best final loss :0.6030515529359672\n",
      "validation_lost 0: 0.6053 , train_loss 0: 0.6036\n",
      "validation_lost 1: 0.6030 , train_loss 1: 0.6035\n",
      "validation_lost 2: 0.6031 , train_loss 2: 0.6037\n",
      "validation_lost 3: 0.6040 , train_loss 3: 0.6030\n",
      "validation_lost 4: 0.6038 , train_loss 4: 0.6032\n",
      "mean validation lost: 0.6039021615878324\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wf = train('Log_reg',tX_std,y_std,0.001,lambda_=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-914badaba4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtX_test_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'outLogRegD23v2.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wk' is not defined"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "# standardize wrt the tx train mean and std\n",
    "def standardize_test(tx, tx_test):\n",
    "    centered_data = tx_test - np.mean(tx, axis=0)\n",
    "    std_data = centered_data / np.std(tx, axis=0)\n",
    "    return std_data\n",
    "tX_test_std = standardize_test(tX, tX_test)\n",
    "OUTPUT_PATH = 'outLogRegD23v2.csv' \n",
    "y_pred = predict_labels(wk, tX_test_std)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wk = np.mean(wf,axis=0)\n",
    "ff = predict_labels(wk[:30], tX_std)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a,b):\n",
    "    t=0\n",
    "    for i in range(len(a)):\n",
    "        if a[i]==b[i]:\n",
    "            t=t+1\n",
    "    print(t/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641216\n"
     ]
    }
   ],
   "source": [
    "acc(y,ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
