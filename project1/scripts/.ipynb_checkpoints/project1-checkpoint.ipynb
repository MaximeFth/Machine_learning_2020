{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "from costs import compute_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "# standardize the data\n",
    "tX_std = standardize(tX)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3323017   0.47014479  0.00198435 ... -0.63936657 -0.63936694\n",
      "  -0.37608954]\n",
      " [ 0.41073016 -1.02905672 -0.15001691 ...  1.57024962  1.56691941\n",
      "   1.22308666]\n",
      " [ 0.43715599  0.57329995  0.36885945 ... -0.63936657 -0.63936694\n",
      "  -0.74543941]\n",
      " ...\n",
      " [ 0.4001554  -0.9083318  -0.34647229 ...  1.56322908  1.56300003\n",
      "   1.35059715]\n",
      " [ 0.46716253  0.48977992 -0.03933471 ...  1.57253686  1.56505567\n",
      "   0.72456329]\n",
      " [ 0.65544596 -0.3530877   1.72560419 ... -0.63936657 -0.63936694\n",
      "  -0.08031989]]\n"
     ]
    }
   ],
   "source": [
    "print(tX_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# least squares GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    # ***************************************************\n",
    "    return (-1/len(y))*tx.T@(y-tx@w)\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"least square gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # compute gradient computes the gradient\n",
    "        gradient = compute_gradient(y,tx,w)\n",
    "        # compute loss. here MSE is used\n",
    "        loss = compute_loss(y,tx,w)\n",
    "        # ***************************************************\n",
    "        # TODO: update w by gradient\n",
    "        w = w-gamma*gradient\n",
    "        # ***************************************************\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.array(losses), np.array(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent: execution time=1.532 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x117539a58>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "# Initialization\n",
    "w_initial = np.zeros(30)\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_losses, gradient_ws = least_squares_GD(y, tX_std, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "plt.plot(gradient_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# least square SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    # ***************************************************\n",
    "    e = y-tx@w\n",
    "    return -1/len(y)*tx.T@e\n",
    "    # ***************************************************\n",
    "\n",
    "\n",
    "def least_squares_SGD(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Least square stochastic gradient descent algorithm.\"\"\"\n",
    "    # ***************************************************\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute random batch\n",
    "        a = batch_iter(y, tx, batch_size, num_batches=1, shuffle=True)\n",
    "        a = list(a)\n",
    "        tx2, y2 = a[0][1], a[0][0]\n",
    "        \n",
    "        # compute gradient & loss\n",
    "        grad = compute_stoch_gradient(y2,tx2,w)\n",
    "        loss= compute_loss(y2, tx2, w)\n",
    "        print(grad)\n",
    "        # update gradient\n",
    "        w = w-gamma*grad\n",
    "        \n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        #print(\"stoch Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              #bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    return np.array(losses), np.array(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[-0.22956179  0.33703679  0.0128398  -0.18711549 -0.13552264 -0.18266247\n",
      " -0.13449967 -0.00885513  0.01169675 -0.14893575  0.18676573 -0.25801643\n",
      " -0.13524255 -0.2249742   0.00261552 -0.00275639  0.02803091  0.00311532\n",
      " -0.00386454 -0.02448859 -0.01398646 -0.13040342 -0.12767184 -0.14878897\n",
      " -0.14166152 -0.14163481 -0.13487747 -0.13516953 -0.13514774 -0.13068457]\n",
      "[-2.10611255e-01  3.12086803e-01  8.53035749e-03 -1.42420375e-01\n",
      " -9.45841587e-02 -1.43915479e-01 -9.35348989e-02 -3.33625226e-02\n",
      "  2.94836069e-02 -1.06166427e-01  1.78896996e-01 -2.24881947e-01\n",
      " -9.42992569e-02 -2.03021107e-01  2.35334867e-03  4.21052170e-03\n",
      "  3.53822534e-02  5.10803049e-05  1.66817318e-03  3.75829891e-05\n",
      " -1.71041327e-03 -8.86480783e-02 -8.19950087e-02 -1.09130396e-01\n",
      " -1.03814695e-01 -1.03843561e-01 -9.35014614e-02 -9.42300363e-02\n",
      " -9.42215570e-02 -8.68706830e-02]\n",
      "[-0.19140369  0.28940688  0.00868243 -0.12219172 -0.0625547  -0.11247945\n",
      " -0.06152828 -0.03949253  0.03701437 -0.08039552  0.17690738 -0.20078559\n",
      " -0.06227254 -0.19760257  0.00557441 -0.00163681  0.03942682 -0.00051182\n",
      " -0.00147671  0.0041442  -0.00245521 -0.06444594 -0.05114976 -0.08566049\n",
      " -0.08165447 -0.08163765 -0.06163659 -0.06219887 -0.06217968 -0.05859796]\n",
      "[-0.1799266   0.27707797  0.01196249 -0.09988022 -0.04084814 -0.0894765\n",
      " -0.03985049 -0.04745085  0.04394792 -0.05609407  0.16071904 -0.18638528\n",
      " -0.04057713 -0.17529792 -0.00097306  0.00200804  0.03729963  0.00118515\n",
      "  0.00626819  0.01795206 -0.00465379 -0.04446995 -0.02644514 -0.06307788\n",
      " -0.05982237 -0.05982694 -0.0395441  -0.0405138  -0.04049524 -0.03453171]\n",
      "[-0.1718577   0.26423095  0.01037369 -0.09430449 -0.03436608 -0.08464705\n",
      " -0.03332712 -0.04982359  0.04705965 -0.04941445  0.15423182 -0.17666233\n",
      " -0.03407813 -0.16415977  0.00195044  0.00465151  0.03324493  0.00218479\n",
      " -0.00269304  0.01025747 -0.00288216 -0.03501417 -0.01872757 -0.05434237\n",
      " -0.05113821 -0.0511582  -0.03304916 -0.03399187 -0.03400527 -0.02828059]\n",
      "[-0.15611107  0.24630153  0.01183392 -0.07676339 -0.02409324 -0.07350623\n",
      " -0.02308454 -0.05352696  0.05125148 -0.03599939  0.15653307 -0.15184601\n",
      " -0.02381345 -0.15794087  0.00200568  0.00465526  0.04115362  0.00450831\n",
      " -0.00471742  0.01527315 -0.00718584 -0.0246401  -0.00777419 -0.04305757\n",
      " -0.04048749 -0.04050955 -0.02266793 -0.02373491 -0.02374444 -0.01564666]\n",
      "[-0.15271896  0.23955298  0.00168243 -0.06833472 -0.01156076 -0.06062511\n",
      " -0.01059941 -0.06531773  0.0454126  -0.02580998  0.14708959 -0.14993853\n",
      " -0.01129181 -0.15246923  0.00060309  0.00525119  0.033481   -0.00447433\n",
      "  0.00360542  0.02389845 -0.00640444 -0.01390887  0.00554182 -0.03306041\n",
      " -0.03111418 -0.03111003 -0.01000678 -0.0112121  -0.01122991 -0.00314212]\n",
      "[-0.14407394  0.22598043  0.00817229 -0.05952894 -0.00732302 -0.05608889\n",
      " -0.00635343 -0.06309325  0.0521051  -0.01931104  0.13996962 -0.13762497\n",
      " -0.00705607 -0.14197432 -0.00345553  0.00454341  0.03490689 -0.00436776\n",
      " -0.00725638  0.02226238 -0.00339117 -0.00522599  0.01259497 -0.02010104\n",
      " -0.01810019 -0.01810313 -0.00593791 -0.00699827 -0.00697383  0.00180907]\n",
      "[-0.13225951  0.21702864  0.01035312 -0.0513394   0.00498756 -0.04362241\n",
      "  0.00595312 -0.06384452  0.0592257  -0.00913813  0.13381923 -0.1294913\n",
      "  0.00525889 -0.13408895  0.00069952  0.00587373  0.03270265 -0.00293324\n",
      "  0.00290717  0.02244437  0.00054555  0.0036895   0.0235033  -0.01596843\n",
      " -0.0144113  -0.01440961  0.0064243   0.00534338  0.00534158  0.01251117]\n",
      "[-0.12330997  0.20699977  0.00935494 -0.04711254  0.01147312 -0.03642512\n",
      "  0.01241326 -0.06654831  0.05502159 -0.00464424  0.12796036 -0.12255671\n",
      "  0.01173563 -0.13000826 -0.00329476  0.00579899  0.02970917 -0.00592857\n",
      " -0.00480076  0.02274279 -0.00155452  0.00842821  0.02956487 -0.0093335\n",
      " -0.00794908 -0.00794902  0.01290459  0.01179484  0.01181509  0.01755696]\n",
      "[-0.12304243  0.19818415  0.010169   -0.05505095 -0.00201212 -0.04978906\n",
      " -0.00106674 -0.05579584  0.04778611 -0.01595576  0.11955149 -0.12478481\n",
      " -0.00174256 -0.13150363  0.00236762  0.01157259  0.0209879  -0.00099155\n",
      " -0.00749866  0.01227936 -0.00193313 -0.00323459  0.01231486 -0.02407227\n",
      " -0.02288569 -0.02287964 -0.00062153 -0.00168832 -0.00165622  0.0065091 ]\n",
      "[-0.11452635  0.19619314  0.01306993 -0.04394285  0.00947532 -0.03906125\n",
      "  0.01041902 -0.06565105  0.04488767 -0.00508077  0.11678648 -0.11325013\n",
      "  0.0097341  -0.12072749 -0.0019403   0.00325514  0.02619822 -0.00475432\n",
      " -0.00577677  0.01771547 -0.0060327   0.00761263  0.03087536 -0.00361212\n",
      " -0.00210407 -0.0021123   0.01054558  0.00980157  0.00981064  0.01570991]\n",
      "[-1.10503072e-01  1.85604631e-01  1.23198777e-02 -4.05649334e-02\n",
      "  1.14375663e-03 -4.49787015e-02  2.07366215e-03 -6.42743255e-02\n",
      "  5.12301203e-02  1.72094346e-04  1.07571167e-01 -1.10181421e-01\n",
      "  1.40523365e-03 -1.09688383e-01  6.24869422e-04  6.92472256e-03\n",
      "  1.89203730e-02 -3.61376041e-03 -6.10567123e-03  1.54595489e-02\n",
      " -6.15234671e-03  1.42161574e-02  2.59764370e-02 -4.12424664e-03\n",
      " -3.24786359e-03 -3.23394568e-03  3.05080782e-03  1.47771166e-03\n",
      "  1.48091775e-03  2.10249821e-02]\n",
      "[-0.1021758   0.17633424  0.00990708 -0.03208799  0.017233   -0.02954784\n",
      "  0.01815177 -0.06523858  0.05457745  0.00870436  0.1059943  -0.10298949\n",
      "  0.01749103 -0.1053911  -0.00479643  0.00954846  0.01692974 -0.00184315\n",
      " -0.00238072  0.02220717 -0.006766    0.021183    0.03920811  0.00252066\n",
      "  0.00304319  0.00302573  0.01880449  0.01756282  0.01757254  0.03056273]\n",
      "[-0.10424837  0.1775522   0.01355115 -0.04606941  0.00512116 -0.04028033\n",
      "  0.0060243  -0.06123746  0.04949876 -0.00633983  0.09575202 -0.10892128\n",
      "  0.0053724  -0.10708866  0.00702139  0.00478889  0.01079127  0.00127679\n",
      "  0.00169277  0.01321585 -0.00743824  0.00913818  0.02375836 -0.01166675\n",
      " -0.01034141 -0.01034806  0.0065909   0.00544455  0.0054633   0.01457333]\n",
      "[-0.09412295  0.16379983  0.00701663 -0.03781059  0.01161431 -0.0343884\n",
      "  0.01251724 -0.06328551  0.05458166 -0.00220723  0.09557566 -0.10144956\n",
      "  0.01186651 -0.10520002  0.00721042 -0.00253349  0.00968457  0.00677085\n",
      " -0.00152435  0.00472534 -0.00145693  0.01252377  0.03586895  0.00310311\n",
      "  0.00507238  0.00504019  0.01293903  0.01192123  0.01195156  0.01926909]\n",
      "[-0.09405586  0.16408529  0.01168191 -0.03774871  0.01028206 -0.03704259\n",
      "  0.01120023 -0.06014185  0.04370469 -0.00262522  0.09287077 -0.09640658\n",
      "  0.01053599 -0.0996548   0.00476221  0.00532356  0.00952278 -0.00047182\n",
      " -0.00774952  0.00829245 -0.00253472  0.0119817   0.03072424 -0.00448065\n",
      " -0.00303314 -0.00303731  0.01163871  0.01058755  0.01060298  0.01754412]\n",
      "[-0.08587102  0.15275542  0.01247832 -0.03766061  0.00399871 -0.04418255\n",
      "  0.00492137 -0.05698023  0.04710651 -0.00529672  0.08274626 -0.09119444\n",
      "  0.00425722 -0.09628387 -0.00065179  0.00317219  0.00077172 -0.00188352\n",
      " -0.00703268  0.00998535  0.00197553  0.0109225   0.03127991  0.00508134\n",
      "  0.00696893  0.0069296   0.00503289  0.00432272  0.00434162  0.01558962]\n",
      "[-0.0830245   0.1507106   0.01852083 -0.03087213  0.01026679 -0.0360116\n",
      "  0.01118325 -0.05823258  0.0344214   0.00474702  0.08352667 -0.08744525\n",
      "  0.01052423 -0.08489095  0.00246616  0.00469853  0.00595261  0.00345218\n",
      "  0.00382212  0.0047966  -0.00364663  0.01874101  0.03223839  0.00317889\n",
      "  0.00406962  0.00407115  0.0116616   0.01058271  0.01059697  0.02367478]\n",
      "[-0.07597452  0.14406171  0.01237454 -0.02919807  0.01486247 -0.02995752\n",
      "  0.01573356 -0.05721282  0.0467062   0.0077158   0.07924422 -0.08422976\n",
      "  0.01510816 -0.09387412 -0.00264924  0.00280722  0.00098549  0.00072951\n",
      " -0.00017433  0.00482915 -0.00278711  0.02212983  0.04059594  0.00802216\n",
      "  0.00865335  0.00865389  0.01624412  0.01517164  0.01518576  0.03035162]\n",
      "[-0.07532479  0.1373239   0.01116207 -0.02975968  0.01145372 -0.03252948\n",
      "  0.01232135 -0.05428171  0.04396631  0.00110727  0.07564952 -0.07954255\n",
      "  0.01169391 -0.09104155  0.00276805 -0.00528772 -0.00377187 -0.00110477\n",
      " -0.00087752  0.01111298 -0.01299983  0.01371464  0.03244755  0.0028088\n",
      "  0.00353725  0.00356725  0.01268867  0.01173386  0.01175574  0.02297363]\n",
      "[-0.06863727  0.13927857  0.01497227 -0.03585445  0.00640832 -0.03857325\n",
      "  0.00730521 -0.04976478  0.0313061  -0.00107967  0.07964923 -0.07864486\n",
      "  0.00665674 -0.09095953  0.00165981 -0.00271679  0.00098324  0.00486691\n",
      " -0.00093687 -0.00568387  0.00165877  0.01276993  0.03243475  0.00510952\n",
      "  0.00669263  0.00666125  0.00779769  0.00671268  0.00672833  0.01930272]\n",
      "[-0.06944547  0.13437809  0.01502685 -0.03575391  0.00508992 -0.03963257\n",
      "  0.00598857 -0.05175819  0.04263055 -0.00407086  0.07436152 -0.08039911\n",
      "  0.00533911 -0.08695433  0.00358459  0.00568924 -0.00161649  0.00058918\n",
      "  0.00570202 -0.00398515  0.00366909  0.01126086  0.02653448 -0.00056648\n",
      "  0.00054848  0.00052437  0.00621383  0.00540876  0.00540022  0.01544111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.49356246e-02  1.27427619e-01  1.87712919e-02 -3.40754902e-02\n",
      "  9.37253536e-03 -3.58039126e-02  1.02629511e-02 -4.85667461e-02\n",
      "  2.49148498e-02  2.87498586e-03  7.69873482e-02 -8.13986898e-02\n",
      "  9.62358632e-03 -8.64521139e-02  2.12187727e-03 -4.21575706e-05\n",
      "  2.01007927e-03  6.19223529e-03 -1.61521719e-03 -4.65409046e-03\n",
      "  3.52944797e-03  1.54192198e-02  3.05840466e-02  1.22653371e-03\n",
      "  1.90718595e-03  1.89832664e-03  1.05916324e-02  9.69753970e-03\n",
      "  9.69491598e-03  2.27093710e-02]\n",
      "[-0.06600394  0.12521683  0.01719337 -0.02978975  0.00157069 -0.04347543\n",
      "  0.00246406 -0.05011815  0.03965076  0.00200959  0.05818398 -0.07933312\n",
      "  0.00181639 -0.07779233  0.00403315  0.00676097 -0.01023232  0.00879653\n",
      "  0.00113376  0.00401243 -0.00449103  0.01623615  0.0277958   0.00374792\n",
      "  0.00448847  0.00447536  0.00307454  0.00187493  0.0018699   0.02246361]\n",
      "[-0.06044898  0.12313728  0.01532522 -0.02880727  0.00940177 -0.03541173\n",
      "  0.01027327 -0.05282136  0.03917351  0.00186359  0.05664    -0.07253014\n",
      "  0.0096431  -0.0743155  -0.0013473   0.00464103 -0.01370574 -0.00482342\n",
      " -0.00510967 -0.00220337 -0.00123993  0.013562    0.03300433  0.00595905\n",
      "  0.00697996  0.00699953  0.01049824  0.0097022   0.009724    0.0222782 ]\n",
      "[-0.0539928   0.11384127  0.01207209 -0.02265144  0.00667719 -0.03838699\n",
      "  0.0075601  -0.05349377  0.0411082   0.00275011  0.05898159 -0.06584083\n",
      "  0.00692015 -0.07278748 -0.0030005   0.00106164 -0.0106808  -0.00125526\n",
      " -0.00133347 -0.00190774 -0.00128359  0.01694195  0.03376544  0.01242165\n",
      "  0.01378407  0.01378497  0.00776645  0.00697889  0.00698276  0.02229434]\n",
      "[-5.26023274e-02  1.12163826e-01  1.20248080e-02 -2.06039548e-02\n",
      "  6.31395474e-03 -3.80429935e-02  7.18152850e-03 -5.10054424e-02\n",
      "  3.93377934e-02  3.00285848e-03  5.55071931e-02 -6.16224853e-02\n",
      "  6.55571957e-03 -7.37407711e-02  7.61283175e-04  6.76538654e-04\n",
      " -1.40654171e-02 -1.10422243e-04  1.36611433e-04  1.49464094e-03\n",
      " -1.91421267e-03  1.99604529e-02  3.14138830e-02  9.27668718e-03\n",
      "  9.83732103e-03  9.82723794e-03  7.48038910e-03  6.62525061e-03\n",
      "  6.62766564e-03  2.35725692e-02]\n",
      "[-0.04943564  0.10461173  0.01928767 -0.03213773  0.00361645 -0.0405518\n",
      "  0.00447573 -0.04191261  0.02782042 -0.00083283  0.05137219 -0.06602025\n",
      "  0.00385553 -0.07426542  0.00239867  0.00694083 -0.01414049  0.00235186\n",
      "  0.00117888 -0.00956383 -0.00275295  0.01546973  0.02635119  0.00094717\n",
      "  0.00193725  0.00191406  0.00500234  0.00393785  0.00392367  0.01918151]\n",
      "[-0.04927118  0.10788686  0.01591844 -0.022396    0.0111523  -0.03493578\n",
      "  0.01203942 -0.04638474  0.04069129  0.00675812  0.05598751 -0.0638541\n",
      "  0.01140274 -0.0666521  -0.00270572  0.00291382 -0.01056496 -0.00186643\n",
      " -0.01099944 -0.00492014 -0.00515328  0.02446977  0.03625052  0.00849871\n",
      "  0.00917396  0.00918159  0.01228171  0.01146318  0.01149744  0.02559674]\n",
      "[-0.03966818  0.10180271  0.02021599 -0.02020576  0.00986091 -0.03492631\n",
      "  0.01071013 -0.04498803  0.03364007  0.00655508  0.04832814 -0.05432002\n",
      "  0.01009723 -0.05862664  0.00562981 -0.00179565 -0.01729725 -0.00172585\n",
      "  0.00206947 -0.00804106 -0.00140411  0.02336484  0.03486269  0.01043145\n",
      "  0.01111667  0.01110097  0.01098688  0.01015125  0.01018184  0.02503755]\n",
      "[-0.04131474  0.09264099  0.01438038 -0.01713353  0.00542377 -0.03642016\n",
      "  0.00625264 -0.04972231  0.03242585  0.00683684  0.04118572 -0.05182512\n",
      "  0.005653   -0.05885676  0.00325732  0.00514748 -0.01980456  0.00353744\n",
      " -0.00279181 -0.00420227  0.00013988  0.02261124  0.03247951  0.01165797\n",
      "  0.01207653  0.01207865  0.00670692  0.00572275  0.00570919  0.0259872 ]\n",
      "[-0.03341434  0.09140146  0.01674697 -0.01744797  0.00386163 -0.03928694\n",
      "  0.00472002 -0.04974394  0.02816963  0.00317437  0.03619749 -0.05828337\n",
      "  0.00409936 -0.05202013  0.00925599 -0.00288738 -0.01846856  0.00660445\n",
      " -0.00605923 -0.00753436 -0.00535787  0.0199408   0.02683873  0.00410993\n",
      "  0.00476709  0.00477678  0.00503228  0.0041734   0.00417543  0.01979969]\n",
      "[-0.04015611  0.09065518  0.01182806 -0.02607753  0.00059332 -0.04219492\n",
      "  0.00145043 -0.04785246  0.0340381  -0.00069442  0.04250639 -0.05433586\n",
      "  0.00083024 -0.06305218 -0.00400063  0.00355796 -0.02133147  0.0045854\n",
      " -0.00290922 -0.01011797  0.00257735  0.01719631  0.02542798  0.00586883\n",
      "  0.00672451  0.00671534  0.00190839  0.00089177  0.00090153  0.01839971]\n",
      "[-0.03888585  0.0891923   0.01741758 -0.02256804  0.00680465 -0.03601944\n",
      "  0.0076588  -0.0434547   0.03360693  0.00093171  0.03422981 -0.05136095\n",
      "  0.00703981 -0.05517158  0.01150514  0.00295689 -0.02465259  0.00632631\n",
      " -0.00607936 -0.01318383 -0.00119849  0.0172185   0.03005467  0.00992238\n",
      "  0.01088015  0.01087232  0.00776158  0.00709612  0.00710795  0.01926502]\n",
      "[-0.03317426  0.08701609  0.02043263 -0.02931235  0.00196454 -0.04028191\n",
      "  0.00278174 -0.03856895  0.02633073 -0.00469449  0.03806761 -0.05490206\n",
      "  0.00218907 -0.06010411  0.00218762 -0.00466145 -0.02429048  0.00410798\n",
      "  0.00251242 -0.02201065 -0.00359613  0.01066961  0.02255738 -0.00012731\n",
      "  0.0007433   0.00075537  0.00286014  0.00226809  0.00227132  0.01366964]\n",
      "[-0.03628463  0.08654186  0.01922398 -0.02661002  0.00471503 -0.0382448\n",
      "  0.00556059 -0.0396434   0.02989471  0.00020432  0.0365629  -0.05108405\n",
      "  0.00494951 -0.0597707  -0.00272742  0.00250946 -0.02619012 -0.00587759\n",
      " -0.00077254 -0.01189383 -0.00363292  0.01380951  0.02867626  0.00618096\n",
      "  0.00719827  0.00720903  0.00597994  0.00500437  0.0050314   0.01980406]\n",
      "[-0.02847719  0.08062375  0.0160573  -0.01710993  0.00851636 -0.0320048\n",
      "  0.0093298  -0.0477458   0.03514417  0.01021975  0.02721037 -0.05464985\n",
      "  0.00873811 -0.04647487  0.0011084  -0.00433355 -0.02231413 -0.00026848\n",
      " -0.00557512 -0.01354935 -0.0007778   0.02471496  0.03084845  0.00514941\n",
      "  0.00491106  0.00493065  0.00988208  0.00878856  0.00880659  0.02771441]\n",
      "[-0.03206891  0.08095681  0.01358759 -0.02099947  0.01055922 -0.03087494\n",
      "  0.01139068 -0.04377668  0.02663469  0.00407653  0.03062904 -0.05292228\n",
      "  0.01078805 -0.05660396  0.00057785  0.00041322 -0.02564513  0.0003529\n",
      " -0.00237121 -0.01311169 -0.00115841  0.01831197  0.03054876  0.00599329\n",
      "  0.00626576  0.00625588  0.01168604  0.0108479   0.010847    0.02352834]\n",
      "[-0.03035574  0.08069358  0.02168266 -0.01657143  0.00993071 -0.0329827\n",
      "  0.01077259 -0.04048033  0.02719769  0.00737602  0.02936202 -0.0447409\n",
      "  0.01016946 -0.0535101  -0.0046927   0.00483571 -0.02555846 -0.00501602\n",
      "  0.00174064 -0.00888021 -0.00217605  0.02306615  0.03369857  0.010255\n",
      "  0.01068631  0.01067088  0.01134876  0.01023629  0.0102339   0.02669646]\n",
      "[-0.02786115  0.07466337  0.02560876 -0.0223123   0.00556949 -0.03796455\n",
      "  0.0064065  -0.03683061  0.01284446  0.00322165  0.03038819 -0.04271714\n",
      "  0.00580442 -0.04818895  0.00607727 -0.00482821 -0.02179468  0.00521385\n",
      "  0.00106984 -0.01894783 -0.00319569  0.01783001  0.02824884  0.00833712\n",
      "  0.0092059   0.00918457  0.00659299  0.00587715  0.00587043  0.01972824]\n",
      "[-2.16444168e-02  7.45044697e-02  2.37412030e-02 -1.68988334e-02\n",
      " -9.42836381e-04 -4.31614667e-02 -9.79993743e-05 -3.63203615e-02\n",
      "  2.73027230e-02  1.83431521e-03  3.02456629e-02 -4.10534427e-02\n",
      " -7.09373495e-04 -4.95381665e-02 -1.11132799e-03  4.60357120e-04\n",
      " -2.63126954e-02 -4.60350978e-03  5.67383628e-03 -1.20478640e-02\n",
      " -4.05928251e-04  1.68165481e-02  2.52651106e-02  8.40717965e-03\n",
      "  8.94616744e-03  8.96670453e-03  2.46708497e-04 -6.58345365e-04\n",
      " -6.40805705e-04  1.94161337e-02]\n",
      "[-0.02877274  0.07315782  0.02471361 -0.01872302 -0.00109951 -0.04294517\n",
      " -0.00026875 -0.03920964  0.02731564  0.00285098  0.02772668 -0.04310988\n",
      " -0.0008701  -0.04829786  0.00472337  0.00275188 -0.02336735  0.00291486\n",
      "  0.0011195  -0.01669618 -0.00419471  0.0185594   0.02448332  0.0061775\n",
      "  0.00647896  0.0065013   0.00018119 -0.00080569 -0.00081085  0.0196696 ]\n",
      "[-0.02249069  0.06791744  0.02289283 -0.02398829  0.0042383  -0.0374824\n",
      "  0.00505067 -0.03457333  0.01414952  0.00095984  0.02486771 -0.04555511\n",
      "  0.00446083 -0.04566798  0.00472955 -0.00071887 -0.02927602  0.00423631\n",
      "  0.00083326 -0.02138914 -0.00213538  0.01859396  0.02692489  0.00627785\n",
      "  0.00710951  0.00711399  0.0053439   0.00450991  0.00454485  0.01816592]\n",
      "[-0.02069944  0.06580987  0.01641519 -0.02156029  0.00320533 -0.03663324\n",
      "  0.00400077 -0.04260821  0.01434146  0.00358096  0.02076143 -0.03671068\n",
      "  0.00342615 -0.04726443  0.0039414   0.00137845 -0.02865258  0.0038893\n",
      " -0.00042858 -0.02302482 -0.00822529  0.01874602  0.02668268  0.00952977\n",
      "  0.00985738  0.00986584  0.00431239  0.00348975  0.00349685  0.02148485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02027383  0.06396361  0.02225607 -0.01857785  0.00084702 -0.0396414\n",
      "  0.00167157 -0.03368458  0.02389418  0.00293644  0.01972995 -0.03741081\n",
      "  0.00106762 -0.044111   -0.00760055  0.00364444 -0.03248288 -0.00623859\n",
      "  0.00096699 -0.01626899  0.00118401  0.01694399  0.02521157  0.00669719\n",
      "  0.00705854  0.00705703  0.00204596  0.00111367  0.00114404  0.0208652 ]\n",
      "[-2.43963414e-02  6.63815336e-02  1.68720395e-02 -2.00002727e-02\n",
      " -1.19298084e-03 -4.22113839e-02 -3.74526830e-04 -3.87079554e-02\n",
      "  2.70975066e-02 -2.79847493e-03  1.68848656e-02 -3.97168216e-02\n",
      " -9.64928083e-04 -4.85232624e-02 -2.00181581e-03 -4.77378437e-05\n",
      " -3.67757682e-02 -4.89562499e-03 -2.85922860e-03 -1.40571479e-02\n",
      " -2.43170670e-03  1.18241285e-02  2.42923874e-02  6.70520594e-03\n",
      "  7.46035095e-03  7.45518476e-03 -2.52797529e-04 -9.01927929e-04\n",
      " -8.99895717e-04  1.60704926e-02]\n",
      "[-2.07327477e-02  6.58015960e-02  2.58561520e-02 -1.56641589e-02\n",
      "  7.28226808e-04 -3.94845313e-02  1.52468425e-03 -3.31784729e-02\n",
      "  1.98162908e-02  2.11699716e-03  2.02328336e-02 -4.06885264e-02\n",
      "  9.48226131e-04 -3.90631890e-02 -2.43837639e-04  7.43816822e-03\n",
      " -2.68910034e-02 -9.19014630e-05  2.03819253e-03 -1.25327740e-02\n",
      " -9.12748755e-04  1.80800384e-02  2.14407381e-02  3.51572927e-03\n",
      "  3.77496557e-03  3.74621543e-03  1.86264421e-03  1.01273168e-03\n",
      "  9.90955458e-04  1.74847956e-02]\n",
      "[-0.01468891  0.06012547  0.01245096 -0.0105003   0.0101771  -0.03064403\n",
      "  0.01097856 -0.04018434  0.02235067  0.00646174  0.02376659 -0.02434784\n",
      "  0.01039553 -0.04414661 -0.00067086  0.00356186 -0.0302913  -0.00014578\n",
      "  0.00024007 -0.01830207 -0.00078096  0.0224845   0.03298992  0.01050785\n",
      "  0.01095411  0.01095296  0.01129975  0.0104468   0.01045873  0.02454153]\n",
      "[-0.01646285  0.06111509  0.02515895 -0.02036177  0.00246141 -0.03886491\n",
      "  0.0033019  -0.03105695  0.02287027  0.0008526   0.02049275 -0.03979038\n",
      "  0.00269238 -0.04734765  0.00240119  0.00048915 -0.03082397 -0.00275136\n",
      " -0.00431405 -0.01625265  0.00261939  0.01679242  0.02514352  0.00460725\n",
      "  0.005128    0.00511744  0.0035908   0.00275948  0.00275884  0.0187719 ]\n",
      "[-0.00966402  0.04967711  0.02098175 -0.01790928 -0.00097388 -0.04115779\n",
      " -0.0001598  -0.03250342  0.01529178  0.00050233  0.02443613 -0.03610916\n",
      " -0.00075165 -0.0529137   0.00242266 -0.00177319 -0.02820363  0.00662527\n",
      "  0.00318264 -0.02506853 -0.00123771  0.01631478  0.02409213  0.00919259\n",
      "  0.0097652   0.00975164  0.00014948 -0.00067409 -0.00066737  0.01904123]\n",
      "[-0.01293957  0.05439528  0.01426923 -0.01248637  0.00166421 -0.03770729\n",
      "  0.00246124 -0.04135578  0.0137015   0.00059221  0.02044165 -0.03347118\n",
      "  0.00188177 -0.04367962 -0.00233704  0.00188904 -0.03064553  0.00157899\n",
      " -0.00079697 -0.02131234 -0.00115846  0.0157274   0.02196471  0.00553606\n",
      "  0.00583786  0.00585341  0.00276547  0.00193367  0.00196116  0.01758563]\n",
      "[-0.01482635  0.053346    0.02227582 -0.00657187  0.00112926 -0.03756058\n",
      "  0.00190812 -0.03781101  0.02005452  0.01204759  0.01716129 -0.03048493\n",
      "  0.0013447  -0.02955223  0.0081186   0.00295444 -0.02872376  0.0077643\n",
      " -0.00274027 -0.01164868  0.00220925  0.02428213  0.02409223  0.00618144\n",
      "  0.00534477  0.00532986  0.00256515  0.00141414  0.00140421  0.02744556]\n",
      "[-0.0128866   0.04525608  0.0128534  -0.00791675  0.0057775  -0.03612998\n",
      "  0.00660315 -0.04148661  0.02158569  0.00505651  0.00986183 -0.03236094\n",
      "  0.00600619 -0.03213448  0.00228631  0.00262617 -0.0362965   0.00303442\n",
      "  0.00076103 -0.01387647  0.0044455   0.02041152  0.0246841   0.00384678\n",
      "  0.00345676  0.00346567  0.00673541  0.00606459  0.00607929  0.02148789]\n",
      "[-0.01349682  0.05043469  0.01954691 -0.01723917 -0.00199225 -0.04015151\n",
      " -0.00124358 -0.03064099  0.01494776 -0.00368649  0.01399638 -0.02960382\n",
      " -0.00178149 -0.03842029 -0.00333824 -0.00221475 -0.03749156 -0.00015858\n",
      " -0.00319988 -0.01588118 -0.00315596  0.01409878  0.01957832  0.00397527\n",
      "  0.00451336  0.00451156 -0.0011507  -0.00170628 -0.00171369  0.01287322]\n",
      "[-0.00771796  0.0511982   0.02507616 -0.01360718 -0.0030915  -0.04142432\n",
      " -0.00231688 -0.03252261  0.01938873  0.00315231  0.01412947 -0.03515622\n",
      " -0.00287876 -0.02882394 -0.00233445  0.00599544 -0.02606759  0.00226408\n",
      " -0.00074846 -0.01474924 -0.00016209  0.01853629  0.01944417  0.00384305\n",
      "  0.00407189  0.00407375 -0.00204629 -0.00280717 -0.00281348  0.01618032]\n",
      "[-0.00884477  0.04646151  0.01550799 -0.01026065  0.00851796 -0.03190781\n",
      "  0.00930545 -0.03501114  0.01457196  0.00423312  0.01789895 -0.03125554\n",
      "  0.00873707 -0.04211131  0.00256144 -0.00033852 -0.03090761  0.00442095\n",
      " -0.00025759 -0.01389948  0.00037978  0.01686213  0.02853304  0.00830666\n",
      "  0.008452    0.00844301  0.00944347  0.00877352  0.00880127  0.02158403]\n",
      "[-1.00420670e-02  4.92418967e-02  1.82236342e-02 -1.42434241e-02\n",
      " -2.41013349e-03 -4.11470505e-02 -1.64718691e-03 -3.43514502e-02\n",
      "  1.07578555e-02 -1.19013505e-03  1.51842354e-02 -3.03090130e-02\n",
      " -2.19556996e-03 -3.60856036e-02 -1.13503668e-03  2.43927797e-03\n",
      " -3.26036442e-02 -1.94900063e-03 -6.26995161e-04 -1.93433131e-02\n",
      "  6.36697590e-05  1.43779061e-02  1.93923718e-02  7.68938515e-04\n",
      "  1.08120450e-03  1.10753926e-03 -1.42246749e-03 -2.13794062e-03\n",
      " -2.13016883e-03  1.41859386e-02]\n",
      "[-0.0113196   0.0517892   0.0258804  -0.01597793 -0.00040061 -0.03903947\n",
      "  0.00039572 -0.02906222  0.01659761  0.00292948  0.01129113 -0.03308386\n",
      " -0.00018232 -0.03263768  0.00192327  0.0072311  -0.03142386  0.00287571\n",
      "  0.00053017 -0.01866141 -0.00322684  0.01359858  0.01956471  0.00372865\n",
      "  0.00386454  0.00387226  0.00083846 -0.00012398 -0.00011195  0.0179951 ]\n",
      "[-6.98614358e-03  4.66468382e-02  3.07343883e-02 -1.46160163e-02\n",
      "  2.45254841e-04 -3.57692640e-02  9.48964964e-04 -2.66779513e-02\n",
      "  1.88861643e-02  1.29968453e-03  1.86644422e-02 -2.68157605e-02\n",
      "  4.35606182e-04 -3.27930037e-02  2.51061311e-03 -3.49337931e-03\n",
      " -2.35578174e-02 -2.57883264e-03 -2.45680196e-03 -2.30765966e-02\n",
      "  7.91225795e-05  1.39560158e-02  2.15372344e-02  7.99762694e-03\n",
      "  8.50804256e-03  8.48119809e-03  9.86024038e-04  4.97697681e-04\n",
      "  5.13261074e-04  1.43358902e-02]\n",
      "[-0.01113752  0.04582491  0.01975472 -0.01422503 -0.00279984 -0.04030867\n",
      " -0.00203717 -0.03391443  0.01263092 -0.00043042  0.01294475 -0.02721565\n",
      " -0.00259315 -0.04084867  0.00203512  0.00714186 -0.03129775  0.00169056\n",
      " -0.00078606 -0.0185206  -0.00281599  0.01329609  0.01818399  0.00322201\n",
      "  0.00344739  0.00343434 -0.00175027 -0.00252391 -0.00251394  0.01587789]\n",
      "[-8.75932630e-03  4.30641950e-02  2.73392740e-02 -8.75407755e-03\n",
      "  6.47086276e-03 -3.06590401e-02  7.23472923e-03 -3.51100930e-02\n",
      "  1.85782207e-02  8.55457915e-03  1.08108469e-02 -2.70061329e-02\n",
      "  6.67649820e-03 -2.81128009e-02  2.09992896e-03 -1.27705353e-03\n",
      " -3.14674699e-02  5.31451737e-04  1.22982930e-05 -1.90110326e-02\n",
      "  2.67845910e-03  2.19411628e-02  2.65381820e-02  9.86363395e-03\n",
      "  9.76678501e-03  9.76793198e-03  7.60623213e-03  6.72978058e-03\n",
      "  6.74102099e-03  2.36106002e-02]\n",
      "[-0.00416589  0.04027892  0.02241384 -0.00630676  0.00691174 -0.03140107\n",
      "  0.00766128 -0.03285644  0.01810936  0.00591998  0.01144314 -0.02272791\n",
      "  0.00711707 -0.03093958 -0.00449245  0.00461641 -0.03072681  0.00270212\n",
      " -0.00654592 -0.0128244   0.00383118  0.0199817   0.02425703  0.00599655\n",
      "  0.00570907  0.00569426  0.00771889  0.00717428  0.00719731  0.02098013]\n",
      "[-4.32311912e-03  3.87195368e-02  2.44806601e-02 -1.29897529e-02\n",
      "  3.18833503e-03 -3.57505796e-02  3.96236563e-03 -3.08745998e-02\n",
      "  1.08178326e-02  4.70551609e-05  7.81781877e-03 -2.85220914e-02\n",
      "  3.39628844e-03 -2.68368197e-02  2.20232683e-03 -8.17375752e-03\n",
      " -3.38020198e-02  5.17676576e-04  1.95884335e-03 -1.90504421e-02\n",
      " -8.49396584e-04  1.36976433e-02  2.17041986e-02  2.08935215e-03\n",
      "  2.54753190e-03  2.54917326e-03  3.89165969e-03  3.45035040e-03\n",
      "  3.45889463e-03  1.38013834e-02]\n",
      "[-0.00081254  0.05017802  0.02457824 -0.01110758 -0.00206713 -0.03918246\n",
      " -0.00132833 -0.02942953  0.01639933  0.00303911  0.01416883 -0.02302793\n",
      " -0.00185941 -0.03041318  0.00463105  0.00395002 -0.02856155  0.00269117\n",
      " -0.00138145 -0.01891145 -0.00021086  0.01757493  0.02049104  0.00645899\n",
      "  0.0067584   0.00675955 -0.0010138  -0.00180053 -0.00179816  0.01697149]\n",
      "[-0.00310964  0.03914668  0.02376115 -0.00778291  0.000192   -0.03669006\n",
      "  0.00094019 -0.03141035  0.01737978  0.00864982  0.0158975  -0.02267574\n",
      "  0.00039684 -0.02907165 -0.00284384  0.0026414  -0.02396659  0.00391675\n",
      " -0.00673071 -0.02170512  0.00190307  0.02138968  0.02176275  0.00674946\n",
      "  0.0064467   0.0064357   0.00141948  0.00044918  0.00045336  0.02225373]\n",
      "[-0.00323023  0.0364916   0.02297839 -0.02006244 -0.00220423 -0.04187912\n",
      " -0.00142696 -0.0235121  -0.00045176 -0.0038536  -0.0017689  -0.02979884\n",
      " -0.00199038 -0.02905089  0.00073004 -0.00217829 -0.04375562 -0.00475824\n",
      " -0.00253521 -0.03072377  0.00159096  0.01114966  0.0130814  -0.00405247\n",
      " -0.00384817 -0.00386741 -0.00111387 -0.00194291 -0.00192786  0.0119437 ]\n",
      "[-0.00388008  0.04076691  0.01134464 -0.01225018 -0.00052871 -0.03927531\n",
      "  0.00024418 -0.03388974  0.01309229 -0.00023443  0.01380345 -0.02614312\n",
      " -0.00031615 -0.03695253  0.00323416  0.0010908  -0.03466978 -0.00210961\n",
      " -0.00017263 -0.02016558  0.00422399  0.01267917  0.01826883 -0.00212011\n",
      " -0.00211237 -0.00212363  0.00050222 -0.00025719 -0.00026392  0.01597747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00345136  0.04222392  0.02582323 -0.00496211  0.00422617 -0.03267048\n",
      "  0.00496939 -0.03334536  0.01332963  0.00546658  0.01418772 -0.02669153\n",
      "  0.00442947 -0.0310547  -0.00099752  0.00039204 -0.02641291 -0.00051376\n",
      " -0.0026652  -0.01659032  0.00854316  0.01796598  0.02115264  0.00266896\n",
      "  0.00211196  0.00209364  0.005018    0.00447873  0.00449958  0.01950008]\n",
      "[-3.91767401e-03  4.26356268e-02  1.74718476e-02 -7.15925347e-03\n",
      "  5.58331544e-03 -3.26229069e-02  6.35344891e-03 -3.62064576e-02\n",
      "  1.24890718e-02  4.67288505e-03  1.19624103e-02 -2.36990938e-02\n",
      "  5.79576779e-03 -3.03103430e-02  5.06506215e-03  7.32178918e-03\n",
      " -3.11967374e-02  3.77354117e-03 -8.20346829e-06 -1.30934928e-02\n",
      "  1.52601625e-03  1.71787677e-02  2.24317474e-02  6.94256231e-03\n",
      "  6.81968229e-03  6.80278651e-03  6.54064242e-03  5.86272314e-03\n",
      "  5.84846979e-03  1.94698803e-02]\n",
      "[-0.00443765  0.03930361  0.02543974 -0.01163509 -0.00664531 -0.04443721\n",
      " -0.00588791 -0.02989474  0.00783988 -0.00230385  0.00867791 -0.03074183\n",
      " -0.00643734 -0.02337616  0.00421684 -0.00578386 -0.03307269  0.00362865\n",
      " -0.00183837 -0.01790229  0.00183647  0.01084251  0.01217087 -0.00308037\n",
      " -0.00300522 -0.00300751 -0.00583354 -0.0063835  -0.00637354  0.01007066]\n",
      "[-0.00050106  0.03886219  0.02596211 -0.00361514  0.00488384 -0.03255362\n",
      "  0.00562651 -0.03059491  0.01044808  0.00743627  0.01469747 -0.02009139\n",
      "  0.00508578 -0.02471471  0.00053911 -0.00220477 -0.02793211  0.0003616\n",
      " -0.00091886 -0.01228241 -0.00034665  0.01788486  0.02496574  0.00937589\n",
      "  0.00938949  0.00939953  0.00590256  0.00513228  0.00515138  0.02071759]\n",
      "[ 0.00362015  0.02882243  0.02113389 -0.00578041  0.00121929 -0.03684103\n",
      "  0.00197973 -0.02748014  0.01122785  0.00469107  0.00809588 -0.0166454\n",
      "  0.00142636 -0.02863409  0.00259765 -0.00375556 -0.03297324  0.00469565\n",
      " -0.00300589 -0.01888808 -0.00357595  0.02246132  0.0232986   0.00638131\n",
      "  0.00639429  0.00637965  0.00214499  0.00149608  0.00149293  0.01950796]\n",
      "[ 0.00012797  0.03400857  0.02415795 -0.01032329  0.00145328 -0.03565948\n",
      "  0.00218319 -0.02375937  0.0124655  -0.00107789  0.00229299 -0.01910476\n",
      "  0.0016553  -0.0278675  -0.00073666  0.00288179 -0.03817623 -0.00276068\n",
      " -0.00626347 -0.01593772  0.00451385  0.01351944  0.02001415  0.00173534\n",
      "  0.00214366  0.00215963  0.00231669  0.00171495  0.00171735  0.0136938 ]\n",
      "[-0.00148719  0.03668604  0.0287091  -0.01355124 -0.00102632 -0.03662191\n",
      " -0.00029823 -0.02245541  0.01519106  0.0018801   0.00987748 -0.02236099\n",
      " -0.00082746 -0.02395397  0.00327307  0.00251291 -0.03333702  0.00263315\n",
      " -0.00234412 -0.02256717 -0.00332681  0.01527508  0.01509009 -0.00095729\n",
      " -0.00134592 -0.00135224 -0.00011593 -0.00077284 -0.00076558  0.01520139]\n",
      "[ 0.00399272  0.02828923  0.02163422 -0.00935394  0.00933976 -0.02835751\n",
      "  0.0100854  -0.02975027  0.0076543   0.00652702  0.00644061 -0.01815036\n",
      "  0.00954282 -0.02623287  0.00325024  0.00087503 -0.0307983   0.00233078\n",
      "  0.00110593 -0.02582059  0.00189797  0.01816011  0.02567699  0.00472206\n",
      "  0.00471834  0.00470297  0.0102213   0.00959107  0.00961351  0.0206366 ]\n",
      "[ 0.00561399  0.03085144  0.02003594 -0.00275499  0.00144829 -0.03524953\n",
      "  0.0021831  -0.03134161  0.01012262  0.00531828  0.01385081 -0.01708636\n",
      "  0.00165327 -0.02808228 -0.0017092  -0.00788489 -0.02496007  0.00340046\n",
      "  0.00342198 -0.01884345 -0.00345583  0.0207616   0.01863746  0.00141571\n",
      "  0.00080624  0.00080531  0.00223409  0.00171057  0.0017004   0.01831831]\n",
      "[ 0.00147458  0.03335657  0.01474941 -0.01103392 -0.00058671 -0.03751555\n",
      "  0.00015275 -0.03168947  0.00433578 -0.00421784  0.00545221 -0.02062269\n",
      " -0.00039088 -0.03428913  0.00338487 -0.00054487 -0.03965397 -0.00042632\n",
      "  0.00582832 -0.02258522 -0.00261072  0.01018194  0.01743824  0.00242963\n",
      "  0.0026913   0.00269904  0.0001228  -0.00032888 -0.00032167  0.01178812]\n",
      "[ 0.00065168  0.02297477  0.01862213  0.00194415 -0.00272715 -0.03857451\n",
      " -0.00198007 -0.0350367   0.01924885  0.00843283 -0.0006514  -0.01454482\n",
      " -0.00252304 -0.01683616  0.00185183 -0.00713872 -0.03948276  0.00328912\n",
      "  0.00295124 -0.00964224  0.00244386  0.02335449  0.01861069  0.00282431\n",
      "  0.00176207  0.00175319 -0.00168012 -0.00247259 -0.0024624   0.02269275]\n",
      "[ 0.00396437  0.02338405  0.01741835 -0.00389538  0.01039259 -0.02671733\n",
      "  0.01114062 -0.03713733  0.01283703  0.00968632  0.00046117 -0.0111723\n",
      "  0.01060174 -0.02228773  0.00107272 -0.0074142  -0.03633442  0.00368215\n",
      "  0.00168    -0.02146188  0.00388599  0.02343395  0.02708871  0.00549054\n",
      "  0.0050931   0.00506082  0.0115468   0.01067906  0.0106623   0.0247103 ]\n",
      "[ 0.00208122  0.03289161  0.03172119 -0.01069262  0.00157964 -0.03332687\n",
      "  0.00228499 -0.01975958  0.01114004  0.00081217  0.00383137 -0.01552608\n",
      "  0.00176879 -0.02657019 -0.00641154 -0.00299103 -0.03158142 -0.00021125\n",
      " -0.00069274 -0.021092    0.00246495  0.0148114   0.01814839 -0.00133755\n",
      " -0.00131224 -0.00129743  0.00228974  0.00181664  0.001838    0.01414373]\n",
      "[ 6.64104915e-03  2.13393386e-02  2.05371926e-02 -4.93947171e-03\n",
      "  1.06537867e-02 -2.66886911e-02  1.13719072e-02 -2.78390333e-02\n",
      "  7.34337796e-03  4.47434619e-03  4.28865202e-03 -1.24838944e-02\n",
      "  1.08512167e-02 -2.70369597e-02 -2.03953162e-03  7.85852211e-03\n",
      " -3.55712191e-02  9.46805527e-05 -4.68382041e-03 -2.45406499e-02\n",
      "  5.04249753e-03  2.04672914e-02  2.36541269e-02  2.23371701e-03\n",
      "  1.87217251e-03  1.84079056e-03  1.13823197e-02  1.09125738e-02\n",
      "  1.09146551e-02  1.94717606e-02]\n",
      "[ 0.00352256  0.02686122  0.02213923 -0.00405303  0.00441093 -0.03298759\n",
      "  0.00516584 -0.03108381  0.00651699  0.00556298  0.002693   -0.0182141\n",
      "  0.00462208 -0.02292772  0.00393144 -0.00023298 -0.03690695  0.00155434\n",
      " -0.00268524 -0.02176473  0.00087006  0.01967696  0.02108706  0.00144057\n",
      "  0.00096567  0.00094425  0.00537895  0.00467622  0.00467231  0.02011799]\n",
      "[ 0.00200514  0.02564361  0.01991438 -0.01033044 -0.00249857 -0.03899663\n",
      " -0.00175064 -0.02843346 -0.01003582 -0.00040713  0.00337888 -0.0141235\n",
      " -0.00229609 -0.02297472 -0.00257667  0.00136586 -0.0349069  -0.00233702\n",
      " -0.00140598 -0.02918471  0.00489203  0.01197811  0.0160558   0.00355515\n",
      "  0.00367366  0.00367062 -0.00176198 -0.0022252  -0.00223219  0.01263084]\n",
      "[ 0.00070803  0.03027124  0.01901953  0.00317698  0.00245473 -0.03340197\n",
      "  0.00315744 -0.03259614  0.01333999  0.00561068  0.00900688 -0.01095121\n",
      "  0.00264417 -0.02890516 -0.00114117 -0.00547563 -0.03185101  0.00184893\n",
      "  0.00128272 -0.00478455  0.00111621  0.0180466   0.02085337  0.00845437\n",
      "  0.007945    0.00791548  0.0031906   0.00269212  0.00270876  0.02040289]\n",
      "[ 6.24580526e-03  3.22739802e-02  2.92454014e-02 -1.19324637e-03\n",
      "  5.59586684e-04 -3.50304481e-02  1.28707512e-03 -2.53955471e-02\n",
      "  4.38401364e-03  6.35404973e-03  1.13906661e-02 -1.16800217e-02\n",
      "  7.57258006e-04 -2.53087777e-02 -4.12707283e-03 -9.82197829e-05\n",
      " -2.57568117e-02 -4.89976502e-03  1.30238020e-03 -1.57923302e-02\n",
      "  1.95427803e-03  1.81146224e-02  1.70486863e-02  1.96774542e-03\n",
      "  1.00206195e-03  9.99361654e-04  1.39930954e-03  8.20003239e-04\n",
      "  8.19631703e-04  1.90862327e-02]\n",
      "[ 0.00337766  0.03101146  0.0270724  -0.00993722 -0.0055792  -0.03977661\n",
      " -0.00490575 -0.02524608  0.00486319  0.00081286  0.00126939 -0.01711454\n",
      " -0.00539434 -0.01768212 -0.00334265  0.00437795 -0.03333781 -0.00394681\n",
      " -0.00132851 -0.02467682 -0.00596705  0.01339711  0.01317141  0.00118227\n",
      "  0.00095612  0.0009831  -0.00474326 -0.00533617 -0.00533047  0.01250761]\n",
      "[ 0.00545285  0.02545107  0.02163304 -0.0122819   0.00321282 -0.03443114\n",
      "  0.00395189 -0.02852921  0.00524029 -0.0008287   0.00421385 -0.0217288\n",
      "  0.00341049 -0.02442424 -0.00288674 -0.00148033 -0.03294941 -0.00216067\n",
      " -0.00028393 -0.02924238  0.00820918  0.01202751  0.01745701 -0.00121287\n",
      " -0.00101718 -0.00100816  0.00387425  0.00345675  0.00347096  0.01202396]\n",
      "[ 0.0012219   0.03132958  0.02437824 -0.00310057  0.00224149 -0.03408477\n",
      "  0.00298303 -0.02800205  0.01462174  0.00609476  0.00589158 -0.01336419\n",
      "  0.00243968 -0.02291584  0.00152045 -0.00275777 -0.03201457  0.00330909\n",
      " -0.00013967 -0.01527966 -0.00096189  0.02041688  0.02084929  0.0057432\n",
      "  0.00550768  0.00547687  0.00324577  0.00249508  0.00248581  0.01964167]\n",
      "[ 0.00369012  0.02880754  0.01720784 -0.00374982 -0.00391192 -0.03948183\n",
      " -0.00320974 -0.03012372  0.00273102 -0.00140898  0.00739322 -0.01843819\n",
      " -0.0037145  -0.02339007  0.00227867 -0.00091945 -0.03131904  0.00544739\n",
      "  0.00526297 -0.01380142  0.00054155  0.01250223  0.01009014 -0.00503418\n",
      " -0.0054162  -0.00542361 -0.00300968 -0.00367636 -0.00364365  0.01073547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00252349  0.03032516  0.02123356 -0.0131376   0.00275431 -0.03171268\n",
      "  0.00343605 -0.02907554 -0.01177354 -0.00219353  0.00413514 -0.01662317\n",
      "  0.00293778 -0.03043994  0.00128348 -0.00040599 -0.03822145  0.00101839\n",
      "  0.00353987 -0.02936152 -0.00267152  0.0123285   0.01731913  0.00182061\n",
      "  0.0018879   0.00189248  0.00341107  0.00299315  0.00298234  0.01297515]\n",
      "[ 0.00367771  0.0268898   0.0269425  -0.0052025   0.00090658 -0.03482092\n",
      "  0.00160277 -0.02401966  0.01280859  0.00164091  0.0028333  -0.00842899\n",
      "  0.00109894 -0.02352828  0.00173158 -0.00193812 -0.0350809   0.00520778\n",
      "  0.00081873 -0.01583568  0.00042117  0.0155444   0.01944576  0.00162763\n",
      "  0.00149451  0.00149366  0.00151036  0.00115972  0.00115171  0.01521426]\n",
      "[ 0.01071372  0.02132342  0.02946931  0.00073915  0.00338092 -0.03132927\n",
      "  0.00408128 -0.02776596  0.0094357   0.01079877  0.00540811 -0.00890832\n",
      "  0.00357194 -0.01271664 -0.00674831  0.0030353  -0.02505358 -0.00511736\n",
      " -0.00051216 -0.01817246 -0.00023572  0.02342778  0.01907832  0.00168679\n",
      "  0.00095376  0.00097473  0.00441568  0.00362509  0.00362888  0.02129553]\n",
      "[ 6.22274288e-03  2.18862897e-02  2.46480097e-02 -1.58918354e-02\n",
      "  1.59351437e-03 -3.53562160e-02  2.31525925e-03 -2.25188280e-02\n",
      " -6.45033599e-03  1.18888343e-03 -1.96150214e-03 -1.80751835e-02\n",
      "  1.78920892e-03 -2.29907112e-02  7.91731496e-03  1.23903291e-03\n",
      " -3.54125556e-02  6.99592152e-03  3.16232293e-05 -3.15055265e-02\n",
      " -3.32605380e-03  1.49342651e-02  1.56304880e-02 -3.70000327e-04\n",
      " -6.66259193e-04 -6.80852569e-04  2.35154693e-03  1.86922448e-03\n",
      "  1.85751910e-03  1.46323971e-02]\n",
      "[ 0.00641572  0.01810861  0.02143539 -0.00729907  0.00059697 -0.03365877\n",
      "  0.00128156 -0.02685948  0.00394539  0.00123937 -0.00308043 -0.01914831\n",
      "  0.00078255 -0.02022451 -0.00374482  0.00040672 -0.04035573 -0.00362318\n",
      "  0.00381551 -0.0240431   0.00243903  0.01469105  0.01470599 -0.0012565\n",
      " -0.00185241 -0.00183254  0.00133945  0.00082072  0.00082594  0.01517231]\n",
      "[ 6.32646896e-03  2.33565432e-02  2.46454194e-02 -1.86009851e-03\n",
      " -7.24569482e-04 -3.55535253e-02 -2.17354129e-05 -2.49208025e-02\n",
      "  6.62164436e-03  2.65982810e-03  1.96146216e-03 -1.65796632e-02\n",
      " -5.34029793e-04 -2.26344877e-02  5.56733772e-03  2.41674251e-03\n",
      " -3.40213904e-02  2.30035505e-03 -1.30176755e-03 -1.72202672e-02\n",
      " -2.34951926e-03  1.91808735e-02  1.50394881e-02  1.08290312e-04\n",
      " -6.43428743e-04 -6.55959136e-04 -9.14133065e-05 -4.74953428e-04\n",
      " -4.76795440e-04  1.59741824e-02]\n",
      "[ 0.00697469  0.02324374  0.02468562 -0.00749196 -0.00239497 -0.03721566\n",
      " -0.0017116  -0.02736456  0.0056715  -0.00152205  0.00120683 -0.01351114\n",
      " -0.0022105  -0.01876099 -0.00147398 -0.00218001 -0.03102789 -0.00093244\n",
      " -0.00878476 -0.0230416  -0.00425649  0.01346841  0.01122632 -0.00523792\n",
      " -0.00537426 -0.00535484 -0.00166792 -0.00216486 -0.00214401  0.00947798]\n",
      "[ 0.00858351  0.01692069  0.02471737 -0.01163877 -0.00105811 -0.0343007\n",
      " -0.00039604 -0.0213956   0.00142357 -0.0002968   0.00300445 -0.01361578\n",
      " -0.00088195 -0.02406212 -0.00146931 -0.0028667  -0.03337704 -0.00015391\n",
      "  0.0002292  -0.02455408  0.00491255  0.01006735  0.01562723 -0.00129334\n",
      " -0.00125979 -0.0012513  -0.00027701 -0.00082592 -0.0008226   0.01266533]\n",
      "[ 0.00227639  0.02855017  0.02456656 -0.00148197  0.00324765 -0.02972243\n",
      "  0.00391816 -0.02976684  0.00285119  0.0082123   0.00456003 -0.00809012\n",
      "  0.00342293 -0.01794195 -0.00408338  0.00376494 -0.02643189  0.00040004\n",
      " -0.00143526 -0.01002206  0.0080321   0.0185691   0.01964303  0.00621561\n",
      "  0.00567129  0.00566471  0.00407098  0.00348307  0.00347722  0.01974734]\n",
      "[ 0.00409962  0.02964951  0.03168635 -0.01071563  0.00186393 -0.03171246\n",
      "  0.00253901 -0.01975334 -0.00264797  0.0031641   0.01080091 -0.01784313\n",
      "  0.00205159 -0.02097235 -0.00395961 -0.00518391 -0.02450915 -0.00334633\n",
      " -0.00256626 -0.02594528 -0.00247704  0.01299229  0.01511479 -0.00213627\n",
      " -0.00257885 -0.00257752  0.00266814  0.00208879  0.00213047  0.01404806]\n",
      "SGD: execution time=13.519 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x141da9438>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from proj1_helpers import batch_iter\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "gamma = 0.02\n",
    "batch_size = 50000\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(30)\n",
    "print(w_initial)\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = least_squares_SGD(\n",
    "    y, tX_std, w_initial,batch_size, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "\n",
    "plt.plot(sgd_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# least square\n",
    "computed by solving for w:  X<sup>T</sup>X * w = X<sup>T</sup>y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_square(y, tx):\n",
    "    w = np.linalg.solve(tx.T@tx,tx.T@y)\n",
    "    return w, compute_loss(y, tx, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls, loss = least_square(y, tX_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lamda):\n",
    "    w = np.linalg.solve(tx.T@tx+lamda*np.eye(tx.shape[1]),tx.T@y)\n",
    "    return w, compute_loss(y, tx, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7779046298744507\n"
     ]
    }
   ],
   "source": [
    "wls, loss = ridge_regression(y, tX_std,0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "def update_weights(tx, y, w, gamma):\n",
    "    #probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    gradient = np.dot(tx.T,  probabilities - y)\n",
    "    w -= gradient*gamma / len(tx)\n",
    "    return w\n",
    "\n",
    "def loss_function_LR(tx, y, w):\n",
    "    #probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    #the error when label=1\n",
    "    error1 = -y*np.log(probabilities)\n",
    "    #the error when label=-1\n",
    "    error2 = (1-y)*np.log(1-probabilities)\n",
    "    #return average of sum of costs\n",
    "    return (error1-error2).mean()\n",
    "\n",
    "\n",
    "# logistic regression function\n",
    "def logistic_regression(y,tx, initial_w,  max_iter, gamma):\n",
    "    losses = []\n",
    "    ws = []\n",
    "    for iter_n in range(max_iter):\n",
    "        w = update_weights(tx, y, initial_w, gamma)\n",
    "        loss = loss_function_LR(tx, y, w)\n",
    "        losses.append(loss)\n",
    "        ws.append(w)\n",
    "    return np.array(losses)[-1], np.array(ws)[-1]\n",
    "\n",
    "#################################################################################\n",
    "def decision_boundary(prob):\n",
    "    return 1 if prob > 0.5 else -1\n",
    "\n",
    "def classify(predictions):\n",
    "    decision_boundary = np.vectorize(decision_boundary)\n",
    "    return decision_boundary(predictions).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_LR_update_weights(tx, y, w, gamma, lambda_):\n",
    "    # probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    gradient = np.dot(tx.T,  probabilities - y) + lambda_ * w\n",
    "    w -= gradient*gamma / len(tx)\n",
    "    return w\n",
    "\n",
    "def reg_LR_loss_function(tx, y, w, lambda_):\n",
    "    y2 = (y+1) / 2\n",
    "    # probabilities array that the label is 1\n",
    "    probabilities = sigmoid(np.dot(tx, w))\n",
    "    # the error when label=1\n",
    "    error1 = -y2*np.log(probabilities)\n",
    "    # the error when label=-1\n",
    "    error2 = (1-y2)*np.log(1-probabilities)\n",
    "    # return average of sum of costs\n",
    "    return (error1-error2).mean()+lambda_/2*np.dot(w.T,w)/ len(tx)\n",
    "\n",
    "\n",
    "# regularized logistic regression function\n",
    "def reg_logistic_regression(y,tx,lambda_, initial_w,  max_iter, gamma):\n",
    "    losses = []\n",
    "    ws = []\n",
    "    for iter_n in range(max_iter):\n",
    "        w = reg_LR_update_weights(tx, y, initial_w, gamma,lambda_)\n",
    "        loss = reg_LR_loss_function(tx, y, w, lambda_)\n",
    "        losses.append(loss)\n",
    "        ws.append(w)\n",
    "    return np.array(losses)[-1], np.array(ws)[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K fold functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute K pairs of validations sets  of length 250 000 / K and train set of size 250 000- 250 000/K\n",
    "def parallel_shuffle(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "def split_cross_KFold(K, tx, y):\n",
    "    temp_tx = np.copy(tx)\n",
    "    temp_y = np.copy(y)\n",
    "    parallel_shuffle(temp_tx,temp_y)\n",
    "    train_set, val_set = [], []\n",
    "    size = temp_tx.shape[0]//K\n",
    "    for i in range(K):\n",
    "        val_set.append((temp_tx[size*i:size+size*i], temp_y[size*i:size+size*i]))\n",
    "        indices = range(size*i,size+size*i)\n",
    "        train_set.append((np.delete(temp_tx, indices, axis = 0),np.delete(temp_y, indices, axis = 0)))\n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions updated for K-fold cross validation\n",
    "we compute now the loss on the validations sets instead of the train ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regularized Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update logistic regression in order to compute loss on validation set\n",
    "def reg_logistic_regression_val(tx_val,y_val,tx_train,y_train, initial_w,  max_iter, gamma,lambda_):\n",
    "    losses_val = []\n",
    "    losses_train = []\n",
    "    ws = []\n",
    "    for iter_n in range(max_iter):\n",
    "        # update weights by gradient descent\n",
    "        \n",
    "        w = reg_LR_update_weights(tx_train, y_train, initial_w, gamma,lambda_)\n",
    "        # compute loss on validation sets according to weights w\n",
    "        loss_train = reg_LR_loss_function(tx_train, y_train, w,lambda_)\n",
    "        loss_val = reg_LR_loss_function(tx_val, y_val, w,lambda_)\n",
    "        losses_train.append(loss_train)\n",
    "        losses_val.append(loss_val)\n",
    "\n",
    "        ws.append(w)\n",
    "            \n",
    "    return np.array(losses_val), np.array(losses_train), np.array(ws)[-1]\n",
    "\n",
    "\n",
    "def evaluate_Kfold_logistic(train_set,validation_set,iters, gamma,K,lambda_=0, plot=1):\n",
    "    graph_train = []\n",
    "    graph_val = []\n",
    "    weigths_final = []\n",
    "    validation_losses = []\n",
    "    train_losses = []\n",
    "\n",
    "    for i in range(K):\n",
    "        max_iters = iters\n",
    "        # Initialization\n",
    "        w_initial = np.zeros(len(train_set[0][0][1]))\n",
    "        # validation set [i][0] is matrice tx of the validation set i\n",
    "        # validation set [i][1] is vector y of the validation set i\n",
    "        validation_loss,train_loss, ws  = reg_logistic_regression_val(validation_set[i][0],validation_set[i][1], train_set[i][0], train_set[i][1], w_initial, max_iters, gamma, lambda_)\n",
    "        validation_losses.append(validation_loss[-1])\n",
    "        train_losses.append(train_loss[-1])\n",
    "\n",
    "        weigths_final.append(ws)\n",
    "        if plot:\n",
    "            graph_val.append(validation_loss)\n",
    "            graph_train.append(train_loss)\n",
    "    if plot:\n",
    "        plt.figure(1)\n",
    "        plt.subplot(211)\n",
    "        G = plt.plot(np.array(graph_val).T)\n",
    "        leg = [\"val \"+str(i) for i in range(K)]\n",
    "        plt.legend(G[:K], leg)\n",
    "        plt.subplot(212)\n",
    "        G2 = plt.plot(np.array(graph_train).T)\n",
    "        leg2 = [\"train \"+str(i) for i in range(K)]\n",
    "        plt.legend(G2[:K], leg2)\n",
    "        \n",
    "    return weigths_final, validation_losses, train_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_SGD_val(tx_val,y_val,tx,y, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Least square stochastic gradient descent algorithm.\"\"\"\n",
    "    # ***************************************************\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute random batch\n",
    "        a = batch_iter(y, tx, batch_size, num_batches=1, shuffle=True)\n",
    "        a = list(a)\n",
    "        tx2, y2 = a[0][1], a[0][0]\n",
    "        \n",
    "        # compute gradient & loss\n",
    "        grad = compute_stoch_gradient(y2,tx2,w)\n",
    "        loss= compute_loss(y_val, tx_val, w)\n",
    "        # update gradient\n",
    "        w = w-gamma*grad\n",
    "        # diminish gamma at each iteration\n",
    "        gamma = gamma - gamma/10\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        #print(\"stoch Gradient Descent({bi}/{ti}): loss={l}\".format(\n",
    "              #bi=n_iter, ti=max_iters - 1, l=loss))\n",
    "\n",
    "    return np.array(losses), np.array(ws)\n",
    "\n",
    "def evalutate_Kfold_SGD(train_set,validation_set,iters, gamma,K,batch_size, plot=1):\n",
    "    graph = []\n",
    "    weigths_final = []\n",
    "    validation_losses = []\n",
    "    train_losses = []\n",
    "    for i in range(K):\n",
    "        max_iters = iters\n",
    "        # Initialization\n",
    "        w_initial = np.zeros(30)\n",
    "        # validation set [i][0] is matrice tx of the validation set i\n",
    "        # validation set [i][1] is vector y of the validation set i\n",
    "        validation_losses, ws  = least_squares_SGD_val(validation_set[i][0],validation_set[i][1], train_set[i][0], train_set[i][1], w_initial,  batch_size, max_iters, gamma)\n",
    "        #compute train_loss\n",
    "        train_loss = loss_function(train_set[i][0], train_set[i][1], ws)\n",
    "        validation_losses.append(validation_loss[-1])\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        weigths_final.append(ws)\n",
    "        \n",
    "        if plot:\n",
    "            graph.append(losses)\n",
    "    if plot:\n",
    "        G = plt.plot(np.array(graph).T)\n",
    "        leg = [\"\"+str(i) for i in range(K)]\n",
    "        plt.legend(G[:K], leg)\n",
    "        \n",
    "    return weigths_final, validation_losses, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# standardize the data\n",
    "tX_std = standardize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put feature exp here\n",
    "\n",
    "def fesquare(tx):\n",
    "    temp = np.copy(tx)\n",
    "    return np.concatenate((temp,temp**2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train function serves to generalize training for each method.\n",
    "def train(Model,gamma,max_iter = 100, batch_size=1, K=5,lambda_=0):\n",
    "    assert( K > 1)\n",
    "    #feature expansion\n",
    "    tX_std_expanded = fesquare(tX_std)\n",
    "    # perform K pairs for the cross validation\n",
    "    train_set, val_set = split_cross_KFold(K, tX_std_expanded, y)\n",
    "    if Model == 'Log_reg':\n",
    "        wf, validation_lost, train_loss = evaluate_Kfold_logistic(train_set, val_set, max_iter,gamma,K,lambda_ )\n",
    "        \n",
    "    if Model == 'SGD':\n",
    "        wf, validation_lost, train_loss = evalutate_Kfold_SGD(train_set, val_set, max_iter ,gamma,K,batch_size,lambda_ )\n",
    "        \n",
    "        \n",
    "    print(f'Function: {Model} used, K = {K}, Best final loss :{np.min(validation_lost)}')\n",
    "    for i in range(len(validation_lost)):\n",
    "        print(f'validation_lost {i}: {str(validation_lost[i])[:6]} , train_loss {i}: {str(train_loss[i])[:6]}')\n",
    "    print(f'mean validation lost: {np.mean(validation_lost)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train('Log_reg',0.0005,lambda_=0.008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "# standardize wrt the tx train mean and std\n",
    "def standardize_test(tx, tx_test):\n",
    "    centered_data = tx_test - np.mean(tx, axis=0)\n",
    "    std_data = centered_data / np.std(tx, axis=0)\n",
    "    return std_data\n",
    "tX_test_std = standardize_test(tX, tX_test)\n",
    "OUTPUT_PATH = 'outLogRegD23v2.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(wf[9], tX_test_std)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
